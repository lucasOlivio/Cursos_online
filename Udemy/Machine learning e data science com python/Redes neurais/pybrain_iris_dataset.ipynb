{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pybrain.datasets.classification import ClassificationDataSet\n",
    "\n",
    "dataset = ClassificationDataSet(4, 1, nb_classes=3)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    dataset.addSample(X[i], y[i])\n",
    "    \n",
    "dataset['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pybrain.datasets.classification.ClassificationDataSet at 0x7f6bfe341cf8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, part_data = dataset.splitWithProportion(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(part_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data, val_data = part_data.splitWithProportion(0.5)\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.supervised.trainers import BackpropTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.outdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.indim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error:  0.718970226324\n",
      "Total error:  0.380512792901\n",
      "Total error:  0.353577433919\n",
      "Total error:  0.344126171644\n",
      "Total error:  0.340663553119\n",
      "Total error:  0.340438361029\n",
      "Total error:  0.339270388262\n",
      "Total error:  0.338422765554\n",
      "Total error:  0.337450414503\n",
      "Total error:  0.336857587355\n",
      "Total error:  0.337205288769\n",
      "Total error:  0.336396706453\n",
      "Total error:  0.335344987011\n",
      "Total error:  0.332823254138\n",
      "Total error:  0.334067807007\n",
      "Total error:  0.335606858559\n",
      "Total error:  0.335249166508\n",
      "Total error:  0.335432552359\n",
      "Total error:  0.335068365229\n",
      "Total error:  0.33468977213\n",
      "Total error:  0.3350716998\n",
      "Total error:  0.33485805549\n",
      "Total error:  0.334615800442\n",
      "Total error:  0.33214068799\n",
      "Total error:  0.335340284163\n",
      "Total error:  0.334417250301\n",
      "Total error:  0.334628565919\n",
      "Total error:  0.334247774175\n",
      "Total error:  0.334469658029\n",
      "Total error:  0.334746955496\n",
      "Total error:  0.328717341852\n",
      "Total error:  0.334856579012\n",
      "Total error:  0.334240882714\n",
      "Total error:  0.334049164332\n",
      "Total error:  0.334461708895\n",
      "Total error:  0.333283481078\n",
      "Total error:  0.333436525617\n",
      "Total error:  0.333134485691\n",
      "Total error:  0.333686171601\n",
      "Total error:  0.33269425571\n",
      "Total error:  0.334426514222\n",
      "Total error:  0.334210413933\n",
      "Total error:  0.333731040637\n",
      "Total error:  0.332705339051\n",
      "Total error:  0.33462206622\n",
      "Total error:  0.332052815917\n",
      "Total error:  0.334283345057\n",
      "Total error:  0.332841032496\n",
      "Total error:  0.332812525631\n",
      "Total error:  0.332887193686\n",
      "Total error:  0.334688032445\n",
      "Total error:  0.333014170834\n",
      "Total error:  0.334199025167\n",
      "Total error:  0.33213073093\n",
      "Total error:  0.334585787554\n",
      "Total error:  0.333764567015\n",
      "Total error:  0.334100453886\n",
      "Total error:  0.33180473882\n",
      "Total error:  0.33416907091\n",
      "Total error:  0.332037706225\n",
      "Total error:  0.333853362527\n",
      "Total error:  0.334192883442\n",
      "Total error:  0.333062956598\n",
      "Total error:  0.332750067058\n",
      "Total error:  0.333321970128\n",
      "Total error:  0.333900549579\n",
      "Total error:  0.33308038123\n",
      "Total error:  0.333731255888\n",
      "Total error:  0.331562741327\n",
      "Total error:  0.333444690363\n",
      "Total error:  0.333007252352\n",
      "Total error:  0.33222324025\n",
      "Total error:  0.334943672684\n",
      "Total error:  0.333248874035\n",
      "Total error:  0.332391738284\n",
      "Total error:  0.330870734649\n",
      "Total error:  0.333261356981\n",
      "Total error:  0.333912103936\n",
      "Total error:  0.333113917271\n",
      "Total error:  0.332433989774\n",
      "Total error:  0.333611539182\n",
      "Total error:  0.333460751506\n",
      "Total error:  0.332403217947\n",
      "Total error:  0.333733320307\n",
      "Total error:  0.333541760276\n",
      "Total error:  0.333865348148\n",
      "Total error:  0.33343322346\n",
      "Total error:  0.333745754047\n",
      "Total error:  0.33238639251\n",
      "Total error:  0.33348971379\n",
      "Total error:  0.329182824277\n",
      "Total error:  0.331650772619\n",
      "Total error:  0.332549952417\n",
      "Total error:  0.330887076099\n",
      "Total error:  0.334436452471\n",
      "Total error:  0.334118767729\n",
      "Total error:  0.331373705711\n",
      "Total error:  0.329950277051\n",
      "Total error:  0.329328373136\n",
      "Total error:  0.333897029464\n",
      "Total error:  0.333858831149\n",
      "('train-errors:', '[0.71897  , 0.380513 , 0.353577 , 0.344126 , 0.340664 , 0.340438 , 0.33927  , 0.338423 , 0.33745  , 0.336858 , 0.337205 , 0.336397 , 0.335345 , 0.332823 , 0.334068 , 0.335607 , 0.335249 , 0.335433 , 0.335068 , 0.33469  , 0.335072 , 0.334858 , 0.334616 , 0.332141 , 0.33534  , 0.334417 , 0.334629 , 0.334248 , 0.33447  , 0.334747 , 0.328717 , 0.334857 , 0.334241 , 0.334049 , 0.334462 , 0.333283 , 0.333437 , 0.333134 , 0.333686 , 0.332694 , 0.334427 , 0.33421  , 0.333731 , 0.332705 , 0.334622 , 0.332053 , 0.334283 , 0.332841 , 0.332813 , 0.332887 , 0.334688 , 0.333014 , 0.334199 , 0.332131 , 0.334586 , 0.333765 , 0.3341   , 0.331805 , 0.334169 , 0.332038 , 0.333853 , 0.334193 , 0.333063 , 0.33275  , 0.333322 , 0.333901 , 0.33308  , 0.333731 , 0.331563 , 0.333445 , 0.333007 , 0.332223 , 0.334944 , 0.333249 , 0.332392 , 0.330871 , 0.333261 , 0.333912 , 0.333114 , 0.332434 , 0.333612 , 0.333461 , 0.332403 , 0.333733 , 0.333542 , 0.333865 , 0.333433 , 0.333746 , 0.332386 , 0.33349  , 0.329183 , 0.331651 , 0.33255  , 0.330887 , 0.334436 , 0.334119 , 0.331374 , 0.32995  , 0.329328 , 0.333897 , 0.333859 ]')\n",
      "('valid-errors:', '[1.84195  , 0.456285 , 0.357112 , 0.328548 , 0.315351 , 0.329426 , 0.324178 , 0.32114  , 0.318999 , 0.316996 , 0.310683 , 0.315443 , 0.317565 , 0.311103 , 0.335161 , 0.311017 , 0.314225 , 0.310369 , 0.309195 , 0.308276 , 0.306966 , 0.309626 , 0.309846 , 0.3217   , 0.30666  , 0.31443  , 0.311697 , 0.319346 , 0.3148   , 0.312822 , 0.318325 , 0.300184 , 0.316237 , 0.318507 , 0.32137  , 0.317801 , 0.325898 , 0.312886 , 0.319206 , 0.322016 , 0.310817 , 0.310998 , 0.317213 , 0.324143 , 0.310566 , 0.314598 , 0.331465 , 0.327619 , 0.328446 , 0.309468 , 0.306309 , 0.309785 , 0.308636 , 0.316964 , 0.331999 , 0.315842 , 0.313317 , 0.316017 , 0.303906 , 0.314533 , 0.330143 , 0.324444 , 0.323403 , 0.313565 , 0.325536 , 0.32103  , 0.315492 , 0.313698 , 0.310139 , 0.320601 , 0.325152 , 0.329567 , 0.336966 , 0.32894  , 0.311844 , 0.326003 , 0.312868 , 0.310198 , 0.319234 , 0.325014 , 0.310883 , 0.317944 , 0.313039 , 0.322295 , 0.317993 , 0.323928 , 0.31742  , 0.315768 , 0.316872 , 0.323108 , 0.311922 , 0.334607 , 0.339083 , 0.312756 , 0.33145  , 0.323403 , 0.321969 , 0.331648 , 0.30425  , 0.328924 , 0.3271   , 0.316127 ]')\n"
     ]
    }
   ],
   "source": [
    "net = buildNetwork(dataset.indim, 3, dataset.outdim)\n",
    "trainer = BackpropTrainer(net, dataset=train_data, learningrate=0.01, momentum=0.1, verbose=True)\n",
    "train_erros, val_erros = trainer.trainUntilConvergence(dataset=train_data, maxEpochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_erros, 'b', val_erros, 'r')\n",
    "\n",
    "trainer.totalepochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error:  0.328645123689\n",
      "Total error:  0.328855081662\n",
      "Total error:  0.327778542227\n",
      "Total error:  0.325458369031\n",
      "Total error:  0.330744250151\n",
      "Total error:  0.3290049527\n",
      "Total error:  0.327322671182\n",
      "Total error:  0.327671661157\n",
      "Total error:  0.328716277962\n",
      "Total error:  0.328481730543\n",
      "Total error:  0.328213725667\n",
      "Total error:  0.328800204762\n",
      "Total error:  0.327388664819\n",
      "Total error:  0.328823975394\n",
      "Total error:  0.328767983082\n",
      "Total error:  0.325925806599\n",
      "Total error:  0.32894207393\n",
      "Total error:  0.328430244916\n",
      "Total error:  0.328058769759\n",
      "Total error:  0.328703896519\n",
      "Total error:  0.328585908707\n",
      "Total error:  0.32469840582\n",
      "Total error:  0.329014017067\n",
      "Total error:  0.328890906521\n",
      "Total error:  0.328411330662\n",
      "Total error:  0.326068281666\n",
      "Total error:  0.326954352175\n",
      "Total error:  0.325545387239\n",
      "Total error:  0.329324942092\n",
      "Total error:  0.326829026628\n",
      "Total error:  0.329091035689\n",
      "Total error:  0.329093473338\n",
      "Total error:  0.326788114755\n",
      "Total error:  0.329053847043\n",
      "Total error:  0.328812513854\n",
      "Total error:  0.328836536404\n",
      "Total error:  0.327372788927\n",
      "Total error:  0.329475574403\n",
      "Total error:  0.327797820169\n",
      "Total error:  0.329538936851\n",
      "Total error:  0.327904824276\n",
      "Total error:  0.328931136959\n",
      "Total error:  0.327804071687\n",
      "Total error:  0.328434361856\n",
      "Total error:  0.328168951548\n",
      "Total error:  0.328907942305\n",
      "Total error:  0.323791156895\n",
      "Total error:  0.330497147253\n",
      "Total error:  0.326024632202\n",
      "Total error:  0.324506957005\n",
      "Total error:  0.329986997004\n",
      "Total error:  0.326535456105\n",
      "Total error:  0.32816365518\n",
      "Total error:  0.328118309053\n",
      "Total error:  0.328077034044\n",
      "Total error:  0.325121043237\n",
      "Total error:  0.324991574066\n",
      "Total error:  0.32585526021\n",
      "Total error:  0.325903198441\n",
      "Total error:  0.327393242367\n",
      "Total error:  0.328631982855\n",
      "Total error:  0.327679866691\n",
      "Total error:  0.328937879005\n",
      "Total error:  0.327761408984\n",
      "Total error:  0.328133900301\n",
      "Total error:  0.328320716368\n",
      "Total error:  0.327287881462\n",
      "Total error:  0.324169945458\n",
      "Total error:  0.33010285464\n",
      "Total error:  0.327019282309\n",
      "Total error:  0.326333241596\n",
      "Total error:  0.329054184472\n",
      "Total error:  0.328399935012\n",
      "Total error:  0.328531185674\n",
      "Total error:  0.328647671655\n",
      "Total error:  0.328472577299\n",
      "Total error:  0.329146882658\n",
      "Total error:  0.328593829889\n",
      "Total error:  0.328250015193\n",
      "Total error:  0.328317080543\n",
      "Total error:  0.327163927241\n",
      "Total error:  0.328537362862\n",
      "Total error:  0.32808529308\n",
      "Total error:  0.327805342054\n",
      "Total error:  0.328261853944\n",
      "Total error:  0.325791836642\n",
      "Total error:  0.328642991643\n",
      "Total error:  0.328820054588\n",
      "Total error:  0.327437651429\n",
      "Total error:  0.327263973811\n",
      "Total error:  0.322422278359\n",
      "Total error:  0.328338768072\n",
      "Total error:  0.32861399799\n",
      "Total error:  0.328739782348\n",
      "Total error:  0.328202087232\n",
      "Total error:  0.328184127956\n",
      "Total error:  0.327859477194\n",
      "Total error:  0.329310803716\n",
      "Total error:  0.328749631111\n",
      "Total error:  0.328320110509\n",
      "Total error:  0.32544745578\n",
      "Total error:  0.329486595369\n",
      "Total error:  0.328422042887\n",
      "Total error:  0.327720862271\n",
      "Total error:  0.327466123874\n",
      "Total error:  0.325591616464\n",
      "Total error:  0.328300544721\n",
      "Total error:  0.328719191962\n",
      "Total error:  0.328414803036\n",
      "Total error:  0.328236662911\n",
      "Total error:  0.328248553675\n",
      "Total error:  0.328264723106\n",
      "Total error:  0.327494011119\n",
      "Total error:  0.328894188101\n",
      "Total error:  0.328277598086\n",
      "Total error:  0.324912174601\n",
      "Total error:  0.328696469139\n",
      "Total error:  0.328843038572\n",
      "Total error:  0.328174545964\n",
      "Total error:  0.327282183695\n",
      "Total error:  0.328271392003\n",
      "Total error:  0.327610503186\n",
      "Total error:  0.328639895026\n",
      "Total error:  0.327768110704\n",
      "Total error:  0.328060808026\n",
      "Total error:  0.324060035699\n",
      "Total error:  0.32749412201\n",
      "Total error:  0.324608097795\n",
      "Total error:  0.324461620972\n",
      "Total error:  0.322060074522\n",
      "Total error:  0.328928331292\n",
      "Total error:  0.329510485966\n",
      "Total error:  0.325484061032\n",
      "Total error:  0.328246107157\n",
      "Total error:  0.328697055853\n",
      "Total error:  0.328557936479\n",
      "Total error:  0.327546541168\n",
      "Total error:  0.328588862579\n",
      "Total error:  0.329212944387\n",
      "Total error:  0.328359620558\n",
      "Total error:  0.327220439372\n",
      "Total error:  0.328724132452\n",
      "Total error:  0.328811516936\n",
      "Total error:  0.328641683781\n",
      "Total error:  0.3254459839\n",
      "Total error:  0.326252148692\n",
      "Total error:  0.328408782207\n",
      "Total error:  0.327515342796\n",
      "Total error:  0.326738113608\n",
      "Total error:  0.326406173611\n",
      "Total error:  0.329599045672\n",
      "Total error:  0.327338228497\n",
      "Total error:  0.32615524759\n",
      "Total error:  0.328920456439\n",
      "Total error:  0.326580282338\n",
      "Total error:  0.328684670552\n",
      "Total error:  0.326798856151\n",
      "Total error:  0.328185068814\n",
      "Total error:  0.326322687248\n",
      "Total error:  0.326848640001\n",
      "Total error:  0.325283406689\n",
      "Total error:  0.329010102861\n",
      "Total error:  0.328102399286\n",
      "Total error:  0.32581204323\n",
      "Total error:  0.327874355957\n",
      "Total error:  0.324635596617\n",
      "Total error:  0.328307535348\n",
      "Total error:  0.326040325116\n",
      "Total error:  0.327451736298\n",
      "Total error:  0.32747439755\n",
      "Total error:  0.327762467955\n",
      "Total error:  0.324560854071\n",
      "Total error:  0.328358291994\n",
      "Total error:  0.327034160955\n",
      "Total error:  0.327405536247\n",
      "Total error:  0.326821914496\n",
      "Total error:  0.32664264481\n",
      "Total error:  0.326805832757\n",
      "Total error:  0.323666033386\n",
      "Total error:  0.327723066295\n",
      "Total error:  0.324447661282\n",
      "Total error:  0.325543305133\n",
      "Total error:  0.325379644285\n",
      "Total error:  0.324047445474\n",
      "Total error:  0.324412482647\n",
      "Total error:  0.322915378864\n",
      "Total error:  0.320289057384\n",
      "Total error:  0.315796048056\n",
      "Total error:  0.313313299504\n",
      "Total error:  0.298602578574\n",
      "Total error:  0.262020462595\n",
      "Total error:  0.213970510942\n",
      "Total error:  0.18170363715\n",
      "Total error:  0.154760467675\n",
      "Total error:  0.130350143458\n",
      "Total error:  0.112050514598\n",
      "Total error:  0.0955448656883\n",
      "Total error:  0.0844260331063\n",
      "Total error:  0.074932640222\n",
      "Total error:  0.0662484370215\n",
      "Total error:  0.0611243911028\n",
      "Total error:  0.0558731461575\n",
      "Total error:  0.0518517801493\n",
      "Total error:  0.0475317570632\n",
      "Total error:  0.0454883611714\n",
      "Total error:  0.0436289308007\n",
      "Total error:  0.0411971978599\n",
      "Total error:  0.0394013828746\n",
      "Total error:  0.0377794613555\n",
      "Total error:  0.0363000680117\n",
      "Total error:  0.0347630918852\n",
      "Total error:  0.034166368972\n",
      "Total error:  0.031409602876\n",
      "Total error:  0.0329170806498\n",
      "Total error:  0.031159593956\n",
      "Total error:  0.0294645962255\n",
      "Total error:  0.0280516542954\n",
      "Total error:  0.0302363580062\n",
      "Total error:  0.0273913748503\n",
      "Total error:  0.0296315642761\n",
      "Total error:  0.0249274233203\n",
      "Total error:  0.0262206621616\n",
      "Total error:  0.0275055857387\n",
      "Total error:  0.028280899515\n",
      "Total error:  0.0263328927592\n",
      "Total error:  0.027496562901\n",
      "Total error:  0.0270499814419\n",
      "Total error:  0.0270822670352\n",
      "Total error:  0.0262478888059\n",
      "Total error:  0.0265193504788\n",
      "Total error:  0.026445272541\n",
      "Total error:  0.0274377376984\n",
      "Total error:  0.0227130522793\n",
      "Total error:  0.0237347279254\n",
      "Total error:  0.0259281986897\n",
      "Total error:  0.0256534418894\n",
      "Total error:  0.0251650948961\n",
      "Total error:  0.026159188374\n",
      "Total error:  0.0242423791424\n",
      "Total error:  0.0267016390822\n",
      "Total error:  0.0232675239617\n",
      "Total error:  0.0241615177712\n",
      "Total error:  0.0256498826523\n",
      "Total error:  0.0251949935874\n",
      "Total error:  0.0251993097107\n",
      "Total error:  0.0247532067909\n",
      "Total error:  0.0235360361321\n",
      "Total error:  0.0224047481673\n",
      "Total error:  0.0252493950748\n",
      "Total error:  0.0245940516286\n",
      "Total error:  0.0249870839132\n",
      "Total error:  0.0244807783503\n",
      "Total error:  0.0231791141376\n",
      "Total error:  0.0247342126501\n",
      "Total error:  0.024716148761\n",
      "Total error:  0.0245085786057\n",
      "Total error:  0.0244909235132\n",
      "Total error:  0.0234073851569\n",
      "Total error:  0.0232198102091\n",
      "Total error:  0.02482095027\n",
      "Total error:  0.0243692144081\n",
      "Total error:  0.0233500972997\n",
      "Total error:  0.0239207233045\n",
      "Total error:  0.0242184499924\n",
      "Total error:  0.023877491647\n",
      "Total error:  0.0226446538532\n",
      "Total error:  0.0243032981474\n",
      "Total error:  0.0236746037186\n",
      "Total error:  0.0221398710919\n",
      "Total error:  0.0242061919634\n",
      "Total error:  0.023262493892\n",
      "Total error:  0.0238707013899\n",
      "Total error:  0.0243923277776\n",
      "Total error:  0.0218203241083\n",
      "Total error:  0.0225832511171\n",
      "Total error:  0.0239582192513\n",
      "Total error:  0.0240072148387\n",
      "Total error:  0.0239610348608\n",
      "Total error:  0.0212658751816\n",
      "Total error:  0.023351421121\n",
      "Total error:  0.0226586436315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total error:  0.0235709583746\n",
      "Total error:  0.0220818874218\n",
      "Total error:  0.0213297975592\n",
      "Total error:  0.0231973638699\n",
      "Total error:  0.0226148769412\n",
      "Total error:  0.022800240671\n",
      "Total error:  0.0240852468962\n",
      "Total error:  0.0231465044237\n",
      "Total error:  0.0231632970162\n",
      "Total error:  0.0222815473815\n",
      "Total error:  0.0235156984376\n",
      "Total error:  0.0221891250074\n",
      "Total error:  0.0228074019581\n",
      "Total error:  0.0232182420673\n",
      "Total error:  0.0219823099572\n",
      "Total error:  0.0222478687165\n",
      "Total error:  0.0222247406441\n",
      "Total error:  0.0223673782783\n",
      "Total error:  0.0218818017016\n",
      "Total error:  0.0238990044373\n",
      "Total error:  0.0235565745132\n",
      "Total error:  0.0188727106111\n",
      "Total error:  0.0238910563769\n",
      "Total error:  0.0235586353797\n",
      "Total error:  0.0230660383697\n",
      "Total error:  0.0234155636647\n",
      "Total error:  0.0217384269137\n",
      "Total error:  0.0222796504377\n",
      "Total error:  0.0229020638003\n",
      "Total error:  0.0226807010084\n",
      "Total error:  0.0222023777363\n",
      "Total error:  0.0218243235983\n",
      "Total error:  0.0233521074264\n",
      "Total error:  0.0208270036452\n",
      "Total error:  0.0225130054664\n",
      "Total error:  0.0208907829996\n",
      "Total error:  0.0203348371778\n",
      "Total error:  0.0216174150806\n",
      "Total error:  0.0212410310728\n",
      "Total error:  0.0217734614436\n",
      "Total error:  0.0224439279637\n",
      "Total error:  0.0223855238771\n",
      "Total error:  0.0210756990518\n",
      "Total error:  0.021135031919\n",
      "Total error:  0.0222731080146\n",
      "Total error:  0.022494929575\n",
      "Total error:  0.0218321239366\n",
      "Total error:  0.0217664239087\n",
      "Total error:  0.0228904475518\n",
      "Total error:  0.0222617497143\n",
      "Total error:  0.0220713153152\n",
      "Total error:  0.0203443451898\n",
      "Total error:  0.021039958045\n",
      "Total error:  0.0217304795602\n",
      "Total error:  0.0203593765072\n",
      "Total error:  0.0231427537157\n",
      "Total error:  0.0219367857142\n",
      "Total error:  0.0221680818356\n",
      "Total error:  0.0217298821363\n",
      "Total error:  0.0215492152449\n",
      "Total error:  0.0215830909826\n",
      "Total error:  0.0206691453186\n",
      "Total error:  0.0222215902688\n",
      "Total error:  0.0224442815085\n",
      "Total error:  0.0207149852061\n",
      "Total error:  0.0207572163211\n",
      "Total error:  0.0215608251397\n",
      "Total error:  0.0224808612262\n",
      "Total error:  0.0203896241754\n",
      "Total error:  0.021514893421\n",
      "Total error:  0.0214677948669\n",
      "Total error:  0.0217608387011\n",
      "Total error:  0.0219293326843\n",
      "Total error:  0.0220413857343\n",
      "Total error:  0.0220333091232\n",
      "Total error:  0.0202020656521\n",
      "Total error:  0.0216296246932\n",
      "Total error:  0.0216479438292\n",
      "Total error:  0.0211406863638\n",
      "Total error:  0.0203322201071\n",
      "Total error:  0.0218626676985\n",
      "Total error:  0.021290035751\n",
      "Total error:  0.021906928117\n",
      "Total error:  0.0211297647381\n",
      "Total error:  0.0206897515172\n",
      "Total error:  0.0205080380888\n",
      "Total error:  0.0186070726786\n",
      "Total error:  0.0215090187903\n",
      "Total error:  0.0214978009599\n",
      "Total error:  0.0208584826246\n",
      "Total error:  0.0212888253807\n",
      "Total error:  0.0201735784382\n",
      "Total error:  0.0213797414185\n",
      "Total error:  0.0211719993889\n",
      "Total error:  0.0201978631294\n",
      "Total error:  0.0208177101619\n",
      "Total error:  0.0214349913147\n",
      "Total error:  0.0209040516216\n",
      "Total error:  0.0213788932608\n",
      "Total error:  0.0213402564287\n",
      "Total error:  0.0213685081312\n",
      "Total error:  0.0217904599447\n",
      "Total error:  0.0196456535879\n",
      "Total error:  0.0221930778368\n",
      "Total error:  0.0203455987987\n",
      "Total error:  0.0207220380034\n",
      "Total error:  0.0210150615813\n",
      "Total error:  0.0218360085756\n",
      "Total error:  0.0210695203443\n",
      "Total error:  0.0205934728858\n",
      "Total error:  0.0208258870657\n",
      "Total error:  0.0206471485602\n",
      "Total error:  0.0212634326009\n",
      "Total error:  0.0209062017279\n",
      "Total error:  0.0206928160312\n",
      "Total error:  0.0194321995664\n",
      "Total error:  0.0182622247619\n",
      "Total error:  0.020657083379\n",
      "Total error:  0.0185910418346\n",
      "Total error:  0.0213330593478\n",
      "Total error:  0.0216380731228\n",
      "Total error:  0.0211729112737\n",
      "Total error:  0.0203812750994\n",
      "Total error:  0.0195454543051\n",
      "Total error:  0.0199513565427\n",
      "Total error:  0.0214824662539\n",
      "Total error:  0.0205332957398\n",
      "Total error:  0.0198789903908\n",
      "Total error:  0.0196548244814\n",
      "Total error:  0.0213049161697\n",
      "Total error:  0.019418956745\n",
      "Total error:  0.0210604742334\n",
      "Total error:  0.0211158847233\n",
      "Total error:  0.0216044759587\n",
      "Total error:  0.0198962649048\n",
      "Total error:  0.0196075357112\n",
      "Total error:  0.0192805042241\n",
      "Total error:  0.0193037212772\n",
      "Total error:  0.021377836229\n",
      "Total error:  0.0204764192245\n",
      "Total error:  0.0215576103256\n",
      "Total error:  0.0206917643032\n",
      "Total error:  0.0195430168528\n",
      "Total error:  0.0212892901447\n",
      "Total error:  0.0210523702676\n",
      "Total error:  0.020429026212\n",
      "Total error:  0.0200857952917\n",
      "Total error:  0.0210714622273\n",
      "Total error:  0.020892527669\n",
      "Total error:  0.0211106403473\n",
      "Total error:  0.0216075637228\n",
      "Total error:  0.0196557300504\n",
      "Total error:  0.0204262348492\n",
      "Total error:  0.0199693368729\n",
      "Total error:  0.020229936714\n",
      "Total error:  0.018634117724\n",
      "Total error:  0.0210519209342\n",
      "Total error:  0.0204263955065\n",
      "Total error:  0.0206776696441\n",
      "Total error:  0.0199137074933\n",
      "Total error:  0.0204853156721\n",
      "Total error:  0.0200703532299\n",
      "Total error:  0.0206672772846\n",
      "Total error:  0.0197243946483\n",
      "Total error:  0.0199322581843\n",
      "Total error:  0.019928999964\n",
      "Total error:  0.0199421819036\n",
      "Total error:  0.0213668213068\n",
      "Total error:  0.0198791381917\n",
      "Total error:  0.0184125771328\n",
      "Total error:  0.0204240925428\n",
      "Total error:  0.0194155139573\n",
      "Total error:  0.0193937569957\n",
      "Total error:  0.0207112938712\n",
      "Total error:  0.0205760802816\n",
      "Total error:  0.0195177311836\n",
      "Total error:  0.0200952109932\n",
      "Total error:  0.0200013205402\n",
      "Total error:  0.0202777829131\n",
      "Total error:  0.0189532759873\n",
      "Total error:  0.0190717641312\n",
      "Total error:  0.0191888744857\n",
      "Total error:  0.0200051468267\n",
      "Total error:  0.0190962648343\n",
      "Total error:  0.0206475120595\n",
      "Total error:  0.0196215979137\n",
      "Total error:  0.0204939730236\n",
      "Total error:  0.0197833552664\n",
      "Total error:  0.0180010450128\n",
      "Total error:  0.0197024720961\n",
      "Total error:  0.0205804973761\n",
      "Total error:  0.0194072489386\n",
      "Total error:  0.0201521037798\n",
      "Total error:  0.0206781652895\n",
      "Total error:  0.0199213736154\n",
      "Total error:  0.0197930867657\n",
      "Total error:  0.0204176604739\n",
      "Total error:  0.0207249358486\n",
      "Total error:  0.0193085613059\n",
      "Total error:  0.0193030132539\n",
      "Total error:  0.0197180898271\n",
      "Total error:  0.0200213492528\n",
      "Total error:  0.0204589723571\n",
      "Total error:  0.0192188647778\n",
      "Total error:  0.0173383446252\n",
      "Total error:  0.0204245905925\n",
      "Total error:  0.0193733451019\n",
      "Total error:  0.020470758197\n",
      "Total error:  0.0183361511284\n",
      "Total error:  0.019871200605\n",
      "Total error:  0.0208879740538\n",
      "Total error:  0.0179632546905\n",
      "Total error:  0.0202994641296\n",
      "Total error:  0.0189332326524\n",
      "Total error:  0.0203668701583\n",
      "Total error:  0.0194036107032\n",
      "Total error:  0.0162275603232\n",
      "Total error:  0.0209965586036\n",
      "Total error:  0.0195993421043\n"
     ]
    }
   ],
   "source": [
    "trainer.trainOnDataset(train_data, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: 1.945253, correct: 2.000000\n",
      "out: 0.026945, correct: 0.000000\n",
      "out: 2.050549, correct: 2.000000\n",
      "out: -0.004033, correct: 0.000000\n",
      "out: 1.992665, correct: 2.000000\n",
      "out: 1.670573, correct: 2.000000\n",
      "out: 1.040882, correct: 1.000000\n",
      "out: 1.719260, correct: 2.000000\n",
      "out: 0.004343, correct: 0.000000\n",
      "out: 2.034745, correct: 2.000000\n",
      "out: 1.917940, correct: 2.000000\n",
      "out: 0.124911, correct: 0.000000\n",
      "out: 0.036980, correct: 0.000000\n",
      "out: 1.029938, correct: 1.000000\n",
      "out: -0.019212, correct: 0.000000\n",
      "out: 0.036129, correct: 0.000000\n",
      "out: 1.402451, correct: 1.000000\n",
      "out: 1.910564, correct: 2.000000\n",
      "out: 2.033519, correct: 2.000000\n",
      "out: 1.019898, correct: 1.000000\n",
      "out: 1.820817, correct: 2.000000\n",
      "out: 0.054404, correct: 0.000000\n",
      "out: 0.011792, correct: 0.000000\n",
      "out: 1.779514, correct: 2.000000\n",
      "out: 1.196963, correct: 1.000000\n",
      "out: 0.001804, correct: 0.000000\n",
      "out: 1.036021, correct: 1.000000\n",
      "out: 1.585239, correct: 2.000000\n",
      "out: 1.742420, correct: 2.000000\n",
      "out: 2.070954, correct: 2.000000\n"
     ]
    }
   ],
   "source": [
    "out = net.activateOnDataset(test_data)\n",
    "for i in range(len(out)):\n",
    "    print('out: %f, correct: %f' % (out[i], test_data['target'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pybrain.datasets.classification.ClassificationDataSet'>\n",
      "<class 'pybrain.datasets.supervised.SupervisedDataSet'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))\n",
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from pybrain.datasets.classification import ClassificationDataSet\n",
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.supervised.trainers import BackpropTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pybrain.datasets.supervised.SupervisedDataSet"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "dataset = ClassificationDataSet(4, 1, nb_classes=3)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    dataset.addSample(X[i], y[i])\n",
    "\n",
    "train_data_temp, part_data_temp = dataset.splitWithProportion(0.6)\n",
    "test_data_temp, val_data_temp = part_data_temp.splitWithProportion(0.5)    \n",
    "\n",
    "type(train_data_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes do _convertToOneOfMany\n",
      "[[2]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [2]]\n",
      "Depois do _convertToOneOfMany\n",
      "[[0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n",
      "---------\n",
      "Erro teste: 6.666667%\n",
      "--------------\n",
      "Erro validação: 3.333333%\n",
      "saida: \t [0 1 0 0 2 0 1 1 0 1 2 1 0 1 1 1 2 2 1 2 2 2 0 2 2 2 2 0 1 1]\n",
      "correto:\t [0 1 0 0 2 0 1 1 0 1 2 2 0 1 1 1 2 2 1 2 2 2 0 2 2 2 2 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "train_data = ClassificationDataSet(4, 1, nb_classes=3)\n",
    "for n in range(train_data_temp.getLength()):\n",
    "    train_data.addSample(train_data_temp.getSample(n)[0], train_data_temp.getSample(n)[1])\n",
    "\n",
    "test_data = ClassificationDataSet(4, 1, nb_classes=3)\n",
    "for n in range(test_data_temp.getLength()):\n",
    "    test_data.addSample(test_data_temp.getSample(n)[0], test_data_temp.getSample(n)[1])\n",
    "\n",
    "val_data = ClassificationDataSet(4, 1, nb_classes=3)\n",
    "for n in range(val_data_temp.getLength()):\n",
    "    val_data.addSample(val_data_temp.getSample(n)[0], val_data_temp.getSample(n)[1])\n",
    "\n",
    "print('Antes do _convertToOneOfMany')\n",
    "print(train_data['target'][:5])\n",
    "\n",
    "train_data._convertToOneOfMany()\n",
    "test_data._convertToOneOfMany()\n",
    "val_data._convertToOneOfMany()\n",
    "\n",
    "print('Depois do _convertToOneOfMany')\n",
    "print(train_data['target'][:5])\n",
    "\n",
    "print('---------')\n",
    "\n",
    "from pybrain.structure.modules import SoftmaxLayer\n",
    "\n",
    "net = buildNetwork(4, 5, 3, outclass=SoftmaxLayer)\n",
    "trainer = BackpropTrainer(net, dataset = train_data, learningrate=0.01, momentum=0.5)\n",
    "trainer.trainOnDataset(train_data, 500)\n",
    "\n",
    "from pybrain.utilities import percentError\n",
    "\n",
    "out = net.activateOnDataset(test_data).argmax(axis=1)\n",
    "print('Erro teste: %f%%' % percentError(out, test_data['class']))\n",
    "\n",
    "print('--------------')\n",
    "\n",
    "import numpy\n",
    "\n",
    "out = net.activateOnDataset(val_data).argmax(axis=1)\n",
    "print('Erro validação: %f%%' % percentError(out, val_data['class']))\n",
    "\n",
    "print('saida: \\t', out)\n",
    "print('correto:\\t', val_data['class'][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
